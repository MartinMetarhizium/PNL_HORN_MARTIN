{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Bot \n",
    "\n",
    "\n",
    "### Alumno: Horn Martín\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"GPUs disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# hiperparametros seleccionados, aumente el max_len y max_vocab para evitar que responda siempre el mismo mensaje\n",
    "MAX_VOCAB_SIZE = 16000\n",
    "MAX_LEN = 15  \n",
    "EMBEDDING_DIM = 300\n",
    "LSTM_UNITS = 128\n",
    "\n",
    "# limpieza de palabras frecuentes\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"\\'d\", \" had\", txt)\n",
    "    txt = re.sub(r\"\\'s\", \" is\", txt)\n",
    "    txt = re.sub(r\"\\'m\", \" am\", txt)\n",
    "    txt = re.sub(r\"don't\", \"do not\", txt)\n",
    "    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    return txt.strip()\n",
    "\n",
    "# carga del dataset\n",
    "with open(\"data_volunteers.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "input_sentences, output_sentences, output_sentences_inputs = [], [], []\n",
    "\n",
    "for line in data:\n",
    "    for i in range(len(line['dialog']) - 1):\n",
    "        chat_in = clean_text(line['dialog'][i]['text'])\n",
    "        chat_out = clean_text(line['dialog'][i + 1]['text'])\n",
    "        if len(chat_in.split()) > MAX_LEN or len(chat_out.split()) > MAX_LEN:\n",
    "            continue\n",
    "        output_sentence = '<sos> ' + chat_out + ' <eos>'\n",
    "        output_sentence_input = '<sos> ' + chat_out\n",
    "        input_sentences.append(chat_in)\n",
    "        output_sentences.append(output_sentence)\n",
    "        output_sentences_inputs.append(output_sentence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenización\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer_inputs.fit_on_texts(input_sentences)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_sentences)\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "num_words_input = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1)\n",
    "\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n",
    "output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "reverse_word2idx_outputs = {idx: word for word, idx in word2idx_outputs.items()}\n",
    "num_words_output = min(MAX_VOCAB_SIZE, len(word2idx_outputs) + 1)\n",
    "\n",
    "# pading\n",
    "encoder_input_sequences = pad_sequences(input_sequences, maxlen=MAX_LEN)\n",
    "decoder_input_sequences = pad_sequences(output_sequences_inputs, maxlen=MAX_LEN)\n",
    "decoder_target_sequences = pad_sequences(output_sequences, maxlen=MAX_LEN)\n",
    "\n",
    "# En este punto cargo los embeddings de FastText\n",
    "embedding_index = {}\n",
    "with open('crawl-300d-2M.vec', encoding='utf8') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        values = line.rstrip().split(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((num_words_input, EMBEDDING_DIM))\n",
    "for word, idx in word2idx_inputs.items():\n",
    "    if idx < num_words_input:\n",
    "        vector = embedding_index.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_matrix[idx] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modelo propiamente dicho\n",
    "encoder_inputs = Input(shape=(MAX_LEN,))\n",
    "encoder_embedding = Embedding(num_words_input, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False)(encoder_inputs)\n",
    "encoder_lstm = LSTM(LSTM_UNITS, return_state=True)\n",
    "_, h, c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "decoder_inputs = Input(shape=(MAX_LEN,))\n",
    "decoder_embedding_layer = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(LSTM_UNITS, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dividimos el dataset:\n",
    "total_size = len(encoder_input_sequences)\n",
    "val_size = int(0.2 * total_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    (encoder_input_sequences[:-val_size], decoder_input_sequences[:-val_size]),\n",
    "    decoder_target_sequences[:-val_size]\n",
    ")).shuffle(buffer_size=1024).batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    (encoder_input_sequences[-val_size:], decoder_input_sequences[-val_size:]),\n",
    "    decoder_target_sequences[-val_size:]\n",
    ")).batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Entrenamiento\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=50, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPUs disponibles: []\n",
      "Epoch 1/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.3896 - loss: 6.4897 - val_accuracy: 0.4972 - val_loss: 2.9451\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.4382 - loss: 3.1560 - val_accuracy: 0.4975 - val_loss: 2.5844\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.4488 - loss: 2.8064 - val_accuracy: 0.5617 - val_loss: 2.4294\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.5200 - loss: 2.6514 - val_accuracy: 0.5820 - val_loss: 2.3261\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.5336 - loss: 2.5335 - val_accuracy: 0.5977 - val_loss: 2.2290\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.5531 - loss: 2.4094 - val_accuracy: 0.6121 - val_loss: 2.1413\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.5686 - loss: 2.3131 - val_accuracy: 0.6246 - val_loss: 2.0713\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.5833 - loss: 2.2237 - val_accuracy: 0.6356 - val_loss: 2.0131\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.5952 - loss: 2.1407 - val_accuracy: 0.6404 - val_loss: 1.9634\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6012 - loss: 2.0701 - val_accuracy: 0.6451 - val_loss: 1.9134\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6072 - loss: 2.0123 - val_accuracy: 0.6587 - val_loss: 1.8439\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6239 - loss: 1.9215 - val_accuracy: 0.6663 - val_loss: 1.7869\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6339 - loss: 1.8580 - val_accuracy: 0.6730 - val_loss: 1.7448\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6450 - loss: 1.7991 - val_accuracy: 0.6769 - val_loss: 1.7116\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6519 - loss: 1.7565 - val_accuracy: 0.6806 - val_loss: 1.6851\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6558 - loss: 1.7213 - val_accuracy: 0.6826 - val_loss: 1.6635\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6605 - loss: 1.6881 - val_accuracy: 0.6933 - val_loss: 1.6456\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6630 - loss: 1.6643 - val_accuracy: 0.6957 - val_loss: 1.6294\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6679 - loss: 1.6307 - val_accuracy: 0.6981 - val_loss: 1.6143\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6708 - loss: 1.6078 - val_accuracy: 0.6999 - val_loss: 1.6020\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6734 - loss: 1.5887 - val_accuracy: 0.7019 - val_loss: 1.5896\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6766 - loss: 1.5681 - val_accuracy: 0.7030 - val_loss: 1.5822\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6782 - loss: 1.5468 - val_accuracy: 0.7055 - val_loss: 1.5714\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.6815 - loss: 1.5262 - val_accuracy: 0.7060 - val_loss: 1.5651\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6833 - loss: 1.5067 - val_accuracy: 0.7077 - val_loss: 1.5560\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6843 - loss: 1.4967 - val_accuracy: 0.7083 - val_loss: 1.5508\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6856 - loss: 1.4817 - val_accuracy: 0.7087 - val_loss: 1.5448\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6862 - loss: 1.4694 - val_accuracy: 0.7104 - val_loss: 1.5396\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6892 - loss: 1.4483 - val_accuracy: 0.7099 - val_loss: 1.5367\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6895 - loss: 1.4391 - val_accuracy: 0.7108 - val_loss: 1.5326\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6920 - loss: 1.4231 - val_accuracy: 0.7111 - val_loss: 1.5321\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6922 - loss: 1.4180 - val_accuracy: 0.7122 - val_loss: 1.5252\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6950 - loss: 1.3957 - val_accuracy: 0.7126 - val_loss: 1.5218\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6962 - loss: 1.3808 - val_accuracy: 0.7126 - val_loss: 1.5202\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6972 - loss: 1.3722 - val_accuracy: 0.7134 - val_loss: 1.5163\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6974 - loss: 1.3653 - val_accuracy: 0.7133 - val_loss: 1.5143\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6992 - loss: 1.3512 - val_accuracy: 0.7139 - val_loss: 1.5127\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.7001 - loss: 1.3386 - val_accuracy: 0.7146 - val_loss: 1.5090\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7013 - loss: 1.3261 - val_accuracy: 0.7143 - val_loss: 1.5096\n",
      "Epoch 40/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7013 - loss: 1.3211 - val_accuracy: 0.7151 - val_loss: 1.5063\n",
      "Epoch 41/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7033 - loss: 1.3085 - val_accuracy: 0.7157 - val_loss: 1.5078\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7047 - loss: 1.2986 - val_accuracy: 0.7160 - val_loss: 1.5050\n",
      "Epoch 43/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7052 - loss: 1.2922 - val_accuracy: 0.7166 - val_loss: 1.5030\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7069 - loss: 1.2780 - val_accuracy: 0.7168 - val_loss: 1.5011\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.7077 - loss: 1.2688 - val_accuracy: 0.7172 - val_loss: 1.5021\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7091 - loss: 1.2581 - val_accuracy: 0.7177 - val_loss: 1.5003\n",
      "Epoch 47/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7097 - loss: 1.2523 - val_accuracy: 0.7178 - val_loss: 1.4996\n",
      "Epoch 48/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7112 - loss: 1.2418 - val_accuracy: 0.7182 - val_loss: 1.4992\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7128 - loss: 1.2309 - val_accuracy: 0.7183 - val_loss: 1.4981\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7130 - loss: 1.2268 - val_accuracy: 0.7194 - val_loss: 1.4954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Aca separamos los modelos por inferencia\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LSTM_UNITS,))\n",
    "decoder_state_input_c = Input(shape=(LSTM_UNITS,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_embed2 = decoder_embedding_layer(decoder_inputs_single)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
    "    decoder_embed2, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")\n",
    "\n",
    "# Función de inferencia implementada:\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    word_counts = {}\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_word2idx_outputs.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word in word_counts:\n",
    "            word_counts[sampled_word] += 1\n",
    "        else:\n",
    "            word_counts[sampled_word] = 1\n",
    "\n",
    "        if (\n",
    "            sampled_word == '<eos>' or\n",
    "            sampled_word == '' or\n",
    "            len(decoded_sentence) > MAX_LEN or\n",
    "            word_counts[sampled_word] > 2\n",
    "        ):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "i love to go to the beach and play video games what about you\n"
     ]
    }
   ],
   "source": [
    "#  Función para consultar el modelo\n",
    "def respond_to_question(input_text):\n",
    "    seq = tokenizer_inputs.texts_to_sequences([clean_text(input_text)])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "    return decode_sequence(padded)\n",
    "\n",
    "# Pruebas realizadas. Son con las que obtuve resultados más cercanos a una respuesta \"real\" por parte del modelo\n",
    "\n",
    "print(respond_to_question(\"Do you like pizza?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "i am a teacher i am a teacher\n"
     ]
    }
   ],
   "source": [
    "print(respond_to_question(\"What do you do for a living?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pude obtener respuestas mucho mejores que las antes mencionadas para este modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
